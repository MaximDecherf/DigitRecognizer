{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python388jvsc74a57bd0c4a6cc1c2df5ddd62d6925b2a7bdee9abacf912eab37272999970e810b9642fd",
   "display_name": "Python 3.8.8 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "c4a6cc1c2df5ddd62d6925b2a7bdee9abacf912eab37272999970e810b9642fd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Live Demo with cam\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2.4.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from tensorflow import keras\n",
    "print(keras.__version__)\n",
    "\n",
    "model = keras.models.load_model('model/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def labels():\n",
    "    res = []\n",
    "    for i in range(0, 28*28):\n",
    "        res.append(\"pixel\" + str(i))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "cap = cv2.VideoCapture()\n",
    "cap.open(0, cv2.CAP_DSHOW)\n",
    "\n",
    "def get_img_contour_thresh(img):\n",
    "    x, y, w, h = 15, 15, 300, 300\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    blur = cv2.GaussianBlur(gray, (35, 35), 0)\n",
    "    ret, thresh1 = cv2.threshold(blur, 70, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "    thresh1 = thresh1[y:y + h, x:x + w]\n",
    "    contours, hierarchy = cv2.findContours(thresh1, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)[-2:]\n",
    "    return img, contours, thresh1\n",
    "\n",
    "try:\n",
    "    while(True):\n",
    "        status, frame = cap.read()\n",
    "        if status:\n",
    "            \n",
    "            img, contours, thresh = get_img_contour_thresh(frame)\n",
    "        \n",
    "            if len(contours) > 0:\n",
    "                contour = max(contours, key=cv2.contourArea)\n",
    "                \n",
    "                if cv2.contourArea(contour) > 2500:\n",
    "                    \n",
    "                    x, y, w, h = cv2.boundingRect(contour)\n",
    "\n",
    "                    newImage = thresh[y:y + h, x:x + w]\n",
    "                    \n",
    "                    resized_image = cv2.resize(newImage, (28, 28))\n",
    "                    df = pd.DataFrame([resized_image.flatten()],columns=labels())\n",
    "                    to_predict = df.values\n",
    "                    to_predict = to_predict/255\n",
    "                    to_predict = to_predict.reshape((1,28, 28,1))\n",
    "\n",
    "                    prediction = model.predict_classes(to_predict)[0]\n",
    "\n",
    "            \n",
    "            x, y, w, h = 15, 15, 300, 300\n",
    "            cv2.rectangle(img, (x, y), (x + w, y + h), (0, 0, 255), 4)\n",
    "\n",
    "            cv2.putText(img, \" The number is : \" + str(prediction), (10, 345),\n",
    "                    cv2.FONT_HERSHEY_COMPLEX, 0.8, (0, 255, 255), 1)\n",
    "\n",
    "            #change the window size to fit screen properly\n",
    "            img = cv2.resize(img, (1000, 600))\n",
    "            cv2.imshow(\"Frame\", img)\n",
    "            cv2.imshow(\"Contours\", thresh)        \n",
    "\n",
    "            \n",
    "            \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            raise Exception('quiting window...')\n",
    "\n",
    "except:\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}